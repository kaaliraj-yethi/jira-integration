{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dda05ca-0cb1-4c6d-b0d6-839d19b81b68",
   "metadata": {},
   "source": [
    "# setup openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887f9fd6-6404-44d5-a2d3-edbb024dfe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a37844-6f83-437c-a59b-566c8c0aaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Prompt the user for the API key\n",
    "api_key = getpass.getpass('Enter your API key: ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# Now you can use the API key with the openai library\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84cedfa-fd06-4504-b736-883670baa9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-index-readers-jira\n",
      "  Using cached llama_index_readers_jira-0.1.4-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jira<4.0.0,>=3.6.0 (from llama-index-readers-jira)\n",
      "  Using cached jira-3.8.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-readers-jira) (0.10.38.post2)\n",
      "Collecting defusedxml (from jira<4.0.0,>=3.6.0->llama-index-readers-jira)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jira<4.0.0,>=3.6.0->llama-index-readers-jira) (23.2)\n",
      "Requirement already satisfied: Pillow>=2.1.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jira<4.0.0,>=3.6.0->llama-index-readers-jira) (10.3.0)\n",
      "Collecting requests-oauthlib>=1.1.0 (from jira<4.0.0,>=3.6.0->llama-index-readers-jira)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jira<4.0.0,>=3.6.0->llama-index-readers-jira) (2.32.2)\n",
      "Collecting requests-toolbelt (from jira<4.0.0,>=3.6.0->llama-index-readers-jira)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.2 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jira<4.0.0,>=3.6.0->llama-index-readers-jira) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.6.6)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2024.5.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.30.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2.2.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (4.66.4)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2.7.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.10.0->jira<4.0.0,>=3.6.0->llama-index-readers-jira) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.10.0->jira<4.0.0,>=3.6.0->llama-index-readers-jira) (2.2.1)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=1.1.0->jira<4.0.0,>=3.6.0->llama-index-readers-jira)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (2.18.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kaaliraj\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-jira) (1.16.0)\n",
      "Using cached llama_index_readers_jira-0.1.4-py3-none-any.whl (3.1 kB)\n",
      "Using cached jira-3.8.0-py3-none-any.whl (77 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: oauthlib, defusedxml, requests-toolbelt, requests-oauthlib, jira, llama-index-readers-jira\n",
      "Successfully installed defusedxml-0.7.1 jira-3.8.0 llama-index-readers-jira-0.1.4 oauthlib-3.2.2 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\kaaliraj\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-readers-jira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880443df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.jira import JiraReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931d46c-bb2b-4774-83d6-c248405e377e",
   "metadata": {},
   "source": [
    "# Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96a9246-6f0b-457d-a245-ade79984fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"kaaliraj@yethi.in\"\n",
    "api_token = \"\"\n",
    "\n",
    "from llama_index.readers.jira import JiraReader\n",
    "\n",
    "reader = JiraReader(\n",
    "    email=email, api_token=api_token, server_url=\"tenjin-automation.atlassian.net\"\n",
    ")\n",
    "documents = reader.load_data(query=\"project = TAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e9ce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='e809572c-e80c-4d1d-8f90-71f82604fe2c', embedding=None, metadata={'id': '38314', 'title': 'Topic Modeling with Requirements, Test Cases and Defects', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-318', 'created_at': '2024-07-08T16:55:30.661+0530', 'updated_at': '2024-07-08T16:55:31.354+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Topic Modeling with Requirements, Test Cases and Defects \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fe2b3dcd-b26b-4016-b90b-ee85edf80aea', embedding=None, metadata={'id': '38313', 'title': 'Lavage R&D', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-317', 'created_at': '2024-07-08T16:48:14.470+0530', 'updated_at': '2024-07-08T16:48:37.470+0530', 'labels': [], 'status': 'In Progress', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Lavage R&D \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3c13ac65-130f-4177-bbc5-9bcaea902180', embedding=None, metadata={'id': '38310', 'title': 'Refactoring RAG', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-316', 'created_at': '2024-07-08T15:38:11.967+0530', 'updated_at': '2024-07-08T15:38:18.451+0530', 'labels': [], 'status': 'In Progress', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Refactoring RAG \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='85d47c63-ddb3-43c2-a1dc-1a8b9e22a015', embedding=None, metadata={'id': '38308', 'title': 'AWS Bedrock', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-315', 'created_at': '2024-07-08T15:34:17.748+0530', 'updated_at': '2024-07-08T15:34:37.265+0530', 'labels': [], 'status': 'In Progress', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='AWS Bedrock \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ac001f68-4aff-46f2-a92b-853f7e740d6c', embedding=None, metadata={'id': '38065', 'title': 'Integration of TD before scenario generation (Upload to assistant)', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-314', 'created_at': '2024-06-27T17:58:30.891+0530', 'updated_at': '2024-07-01T11:09:32.579+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Integration of TD before scenario generation (Upload to assistant) \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fb5cf354-a207-4d2c-b68c-45e6a8b3873e', embedding=None, metadata={'id': '38058', 'title': 'Continue for brd scenarios', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-313', 'created_at': '2024-06-27T13:38:15.216+0530', 'updated_at': '2024-06-27T13:38:30.008+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Subtask', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Continue for brd scenarios \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e7e0c464-0940-4cf7-b625-595901f84946', embedding=None, metadata={'id': '38057', 'title': 'Continue for cm scenarios', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-312', 'created_at': '2024-06-27T13:37:48.474+0530', 'updated_at': '2024-06-27T13:38:21.350+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Subtask', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Continue for cm scenarios \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f92fff14-c95e-488d-ae45-60d39dee0cca', embedding=None, metadata={'id': '37974', 'title': 'Create business process for BRD', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-311', 'created_at': '2024-06-21T17:31:37.825+0530', 'updated_at': '2024-07-08T16:49:48.093+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Create business process for BRD \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='abff7597-abd6-42e6-b1e5-08d0c6bb6d91', embedding=None, metadata={'id': '37972', 'title': 'have to make different Apis for test steps and data', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-309', 'created_at': '2024-06-21T17:29:40.198+0530', 'updated_at': '2024-07-01T11:08:21.526+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='have to make different Apis for test steps and data \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='819f56d0-3b36-4107-8b90-90f829a1f856', embedding=None, metadata={'id': '37971', 'title': 'OpenAI Response is breaking (Continue)', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-308', 'created_at': '2024-06-21T17:27:31.485+0530', 'updated_at': '2024-07-08T16:46:10.734+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='OpenAI Response is breaking (Continue) \\n ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='96a4abfd-92a7-4faf-af85-399967afa5ed', embedding=None, metadata={'id': '37970', 'title': 'Provide an option to generate test steps and test data', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-307', 'created_at': '2024-06-21T17:25:09.844+0530', 'updated_at': '2024-06-27T18:45:50.177+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Provide an option to generate test steps and test data \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0214717c-07c9-4052-91bb-48c6c8a146ab', embedding=None, metadata={'id': '37969', 'title': 'not able to upload test design in UI', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-306', 'created_at': '2024-06-21T17:24:25.564+0530', 'updated_at': '2024-06-27T18:40:39.072+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='not able to upload test design in UI \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='df3e6aa5-29e6-42a7-9af5-5a98cae9b237', embedding=None, metadata={'id': '37968', 'title': 'reorder of rows and columns in design results page', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-305', 'created_at': '2024-06-21T17:21:26.513+0530', 'updated_at': '2024-07-01T11:09:32.561+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='reorder of rows and columns in design results page \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b11ec24d-89f9-41d1-9221-45a8607699ea', embedding=None, metadata={'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Jira Integration for requirements documents for test design \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9c4d45ab-e801-4584-81b3-ee7f85208219', embedding=None, metadata={'id': '37883', 'title': 'Move coverage matrix to openai assistant', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-303', 'created_at': '2024-06-17T13:07:14.100+0530', 'updated_at': '2024-07-01T11:07:44.221+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Move coverage matrix to openai assistant \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='70b4a63f-0c04-4935-bf59-bf40d3f91f89', embedding=None, metadata={'id': '37875', 'title': 'Evaluation of Internal LLM', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-302', 'created_at': '2024-06-17T12:22:39.101+0530', 'updated_at': '2024-07-01T11:09:32.126+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Evaluation of Internal LLM \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='31f79565-04a0-446f-b486-605611b1d71f', embedding=None, metadata={'id': '37874', 'title': 'Finetuning on RTM data', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-301', 'created_at': '2024-06-17T12:17:44.789+0530', 'updated_at': '2024-07-01T11:09:32.125+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Finetuning on RTM data \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='f3889d96-48f4-47f2-8724-4b7fc434649e', embedding=None, metadata={'id': '37873', 'title': 'Coverage Matrix to be brought into RAG', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-300', 'created_at': '2024-06-17T12:16:35.701+0530', 'updated_at': '2024-07-01T11:09:32.123+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Coverage Matrix to be brought into RAG \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='27e2f552-98c3-4955-9617-085bfeb8c2a8', embedding=None, metadata={'id': '37872', 'title': 'Scenarios are missing', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-299', 'created_at': '2024-06-17T12:06:06.092+0530', 'updated_at': '2024-06-21T17:11:30.157+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Scenarios are missing \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d022f66e-7c70-4f32-8408-48c01c11b60e', embedding=None, metadata={'id': '37743', 'title': 'Test Scenario or Cases are not generated in sequence as per the requirement document', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-298', 'created_at': '2024-06-10T10:34:00.885+0530', 'updated_at': '2024-06-10T10:34:01.063+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Test Scenario or Cases are not generated in sequence as per the requirement document \\n The test scenarios generated are not in sequence as per the BRD or Coverage Matrix.\\n\\nThe requirement mentioned in last in the BRD is updated as 1st Test scenario.\\n\\nExample:   In Loans, Disbursement is covered as 1st Scenario and Loan creation is shown as 2nd or 3rd Scenario.\\n\\nSimilarly, we observed that same behavior for Test cases in few times. ( Inconsistant)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2891d4ae-5c4f-472a-a338-8f51520aa2c7', embedding=None, metadata={'id': '37736', 'title': 'delete tenant API is not working', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-297', 'created_at': '2024-06-07T15:44:43.782+0530', 'updated_at': '2024-06-17T12:13:58.042+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='delete tenant API is not working \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ab51e23f-c640-45a1-b051-76b57c3d9523', embedding=None, metadata={'id': '37732', 'title': 'User should upload the file with the exsisting uploaded file name but It overrride the data with current file', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-296', 'created_at': '2024-06-07T13:10:49.769+0530', 'updated_at': '2024-06-07T13:10:49.838+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='User should upload the file with the exsisting uploaded file name but It overrride the data with current file \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b2188a82-264a-4744-8895-73b33b1d4590', embedding=None, metadata={'id': '37731', 'title': 'File is uploaded in Requirement Repo then it should allow to upload with the same name in Test Design and Defect', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-295', 'created_at': '2024-06-07T13:07:53.563+0530', 'updated_at': '2024-06-12T15:12:35.624+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='File is uploaded in Requirement Repo then it should allow to upload with the same name in Test Design and Defect \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='14b5da0d-b9c9-49cb-90ec-926e92995b40', embedding=None, metadata={'id': '37728', 'title': 'User context with load more to be added to DB and displayed to user along with scenarios', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-294', 'created_at': '2024-06-07T12:02:53.861+0530', 'updated_at': '2024-07-08T16:49:24.480+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='User context with load more to be added to DB and displayed to user along with scenarios \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ed3cf0e9-20f9-4b3e-9f75-19e79dc69975', embedding=None, metadata={'id': '37726', 'title': 'sample issue created - testing the capability and integration with llama index', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-293', 'created_at': '2024-06-07T11:37:44.794+0530', 'updated_at': '2024-06-07T11:37:45.938+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Story', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='sample issue created - testing the capability and integration with llama index \\n h1. Lorem Ipsum\\n\\nh4. _\"Neque porro quisquam est qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit...\"_\\n\\nh5. \"There is no one who loves pain itself, who seeks after it and wants to have it, simply because it is pain...\"\\n\\n----\\n\\nh2. What is Lorem Ipsum?\\n\\n*Lorem Ipsum* is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry\\'s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum\\n\\n\\n\\n\\n\\n!image-20240607-060531.png|width=536,height=354,alt=\"image-20240607-060531.png\"!\\n\\n\\n\\n||Company||Contact||Country||\\n|Alfreds Futterkiste|Maria Anders|Germany|\\n|Centro comercial Moctezuma|Francisco Chang|Mexico|\\n|Ernst Handel|Roland Mendel|Austria|\\n|Island Trading|Helen Bennett|UK|\\n|Laughing Bacchus Winecellars|Yoshi Tannamuri|Canada|\\n|Magazzini Alimentari Riuniti|Giovanni Rovelli|Italy|', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4b8c8e98-9cb2-4490-a7ef-9d8070143f5d', embedding=None, metadata={'id': '37635', 'title': 'Flow chart diagram-based test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-292', 'created_at': '2024-06-05T12:19:20.955+0530', 'updated_at': '2024-06-17T13:07:39.052+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Flow chart diagram-based test design \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ab74fb35-0844-495c-8174-cb755efbb489', embedding=None, metadata={'id': '37628', 'title': 'Along with free text, coverage checkpoints to be provided during generate more scenarios', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-291', 'created_at': '2024-06-05T11:10:27.396+0530', 'updated_at': '2024-06-17T13:05:24.626+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Along with free text, coverage checkpoints to be provided during generate more scenarios \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='214a61be-ebbf-4138-af09-e0e779f0c009', embedding=None, metadata={'id': '37627', 'title': 'refactoring RAG based on suggested changes', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-290', 'created_at': '2024-06-05T11:06:48.447+0530', 'updated_at': '2024-06-17T13:08:39.452+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='refactoring RAG based on suggested changes \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='97b4232e-3cdc-4691-9cc0-486c31d0ae09', embedding=None, metadata={'id': '37534', 'title': 'Self-healing with GPT - 4.o', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-289', 'created_at': '2024-06-03T11:49:22.834+0530', 'updated_at': '2024-06-03T11:49:38.426+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Self-healing with GPT - 4.o \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='603b1b28-20e3-44ad-bda5-afe9bbb56f98', embedding=None, metadata={'id': '37533', 'title': 'Testing of test case generation API integration with online', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-288', 'created_at': '2024-06-03T11:45:57.215+0530', 'updated_at': '2024-06-21T17:12:27.192+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Testing of test case generation API integration with online \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b846047b-8e27-436b-a56a-f90c737f4162', embedding=None, metadata={'id': '37532', 'title': 'User should be able to go back and select different set of scenarios to generate test cases', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-287', 'created_at': '2024-06-03T11:42:41.628+0530', 'updated_at': '2024-06-05T11:03:15.440+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='User should be able to go back and select different set of scenarios to generate test cases \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='89b52d52-628b-4923-adf1-2bacb84b6a6e', embedding=None, metadata={'id': '37531', 'title': 'System prompts and user prompts are getting combined', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-286', 'created_at': '2024-06-03T11:41:38.790+0530', 'updated_at': '2024-06-17T12:15:15.944+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='System prompts and user prompts are getting combined \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1f513714-2f69-425f-863e-2b2b0ac98f3a', embedding=None, metadata={'id': '37530', 'title': 'Generate more test cases button to be enabled ', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-285', 'created_at': '2024-06-03T11:39:36.137+0530', 'updated_at': '2024-06-21T17:19:20.491+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Generate more test cases button to be enabled  \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dd9b5bd0-a874-4d57-9671-ba6086c7bbd4', embedding=None, metadata={'id': '37529', 'title': 'Pagination', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-284', 'created_at': '2024-06-03T11:38:07.852+0530', 'updated_at': '2024-06-17T13:06:38.777+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Pagination \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='56040805-2ea6-4839-9352-fa1c98d28dc6', embedding=None, metadata={'id': '37528', 'title': 'File upload API should accept multiple files at once', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-283', 'created_at': '2024-06-03T11:37:50.007+0530', 'updated_at': '2024-06-17T12:14:53.083+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='File upload API should accept multiple files at once \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='97bb633e-f516-496f-8511-e99a447a498b', embedding=None, metadata={'id': '37491', 'title': 'User should upload multiple files at a time', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-282', 'created_at': '2024-05-30T18:26:46.901+0530', 'updated_at': '2024-06-07T11:41:46.525+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='User should upload multiple files at a time \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='81bbaf78-acc9-4801-9652-8187c281596f', embedding=None, metadata={'id': '37465', 'title': 'Test Scenario Count is incorrectly displayed while generating Test Scenarios', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-281', 'created_at': '2024-05-29T16:02:30.220+0530', 'updated_at': '2024-06-06T14:50:08.791+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Test Scenario Count is incorrectly displayed while generating Test Scenarios \\n Overall Count is incorrectly displayed while generating Test Scenarios.\\n\\nPlease refer the Screenshot', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='cea5db9b-4cdb-44d9-b305-a4027c8ce660', embedding=None, metadata={'id': '37451', 'title': 'No of Test Scenarios and cases generated were Inconsistent for the same Requirement document', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-280', 'created_at': '2024-05-28T15:54:53.920+0530', 'updated_at': '2024-06-06T14:50:49.062+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='No of Test Scenarios and cases generated were Inconsistent for the same Requirement document \\n No of Test Scenarios and cases generated were Inconsistent for the same Requirement document.\\n\\n\\n\\nEg: \\n\\nDay 1 Coverage matrix generated 231 Test Scenarios and 935 Test Cases were generated.\\n\\nDay 2: 72 Test Scenarios are generated, and 267 Test Cases were generated.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='c6a7dc76-4745-4af6-a6ec-6923ad265d12', embedding=None, metadata={'id': '37450', 'title': 'Test Data Not captured for Coverage Matrix.  Only for BRD its captured', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-279', 'created_at': '2024-05-28T15:50:35.083+0530', 'updated_at': '2024-06-06T14:51:01.821+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Test Data Not captured for Coverage Matrix.  Only for BRD its captured \\n Test Data Not captured for Coverage Matrix.   The column updated with blank data.\\n\\nOnly for BRD its captured.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='39a1b199-4a62-44a0-bf77-e70eedae6799', embedding=None, metadata={'id': '37392', 'title': 'Scenarios and Cases were partially captured', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-278', 'created_at': '2024-05-27T09:13:59.389+0530', 'updated_at': '2024-06-06T14:51:10.195+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Scenarios and Cases were partially captured \\n Please find critical Issues observations below with the attachments.\\n\\n\\xa0\\n\\n# Scenario missed for creating View option to check the status of the import bills.(EXIM_iDCTF_2.2, 4.1)\\n# Import Letter of Credit issuance Issue date - Scenario captured but test cases generated for normal checks like \"the date should be in dd-mm-yyy column\" and not generated for actual requirement like \"back value date, future date and current date\".(Import LC_design A10,A11,A12)\\n# System should generate AMND event, CLIQ event in Import \"\"Letter of Credit\"\" \\xa0Amendments after authorization -Missing test case.(Import LC_design A38)\\n# CLOS event should generate after \"\"Letter of Credit\"\" Cancellation - Test Case not generated for CLOS event.(Import LC_design A49).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e40aa278-69c3-4ef8-a17b-293f13a5d560', embedding=None, metadata={'id': '37372', 'title': 'Scenarios incorrectly generated when two different applications are mapped in a table.', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-277', 'created_at': '2024-05-24T17:05:19.405+0530', 'updated_at': '2024-06-06T14:51:39.725+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"Scenarios incorrectly generated when two different applications are mapped in a table. \\n # Scenarios are captured by mixing two applications (Online Banking and Mobile Banking). When document has common requirement for two Applications Scenario's should be generated for each Application separately.\\n# Scenarios are captured by mixing two user types and Incorrect scenario Mapping for Users\\nExample: Retail user and corporate user cases are covered under same Scenarios.\\n# When BRD has Region Specific Functionalities, Scenarios should capture specific to each region. as of now it is not considered.\\n\\n\\n\\nPlease refer the below section in the attached BRD.\\n\\nSection 2.2 - Page Number 13.\\n\\nSection 3.1.3 - Page Number 14\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fc548745-9e62-41f3-b626-29216f802c71', embedding=None, metadata={'id': '37371', 'title': 'Scenarios not captured from the Table but captured the requirement before and after table.', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-276', 'created_at': '2024-05-24T17:04:36.786+0530', 'updated_at': '2024-06-06T14:51:56.929+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Scenarios not captured from the Table but captured the requirement before and after table. \\n Scenarios are not captured for the requirement in the Table (Page Number 10).  Ther requirements before and after were captured.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e43cbe12-7b3b-4f87-8623-475eb46a2a02', embedding=None, metadata={'id': '37370', 'title': 'Scenarios not properly captured when the requirement is having OBLIQUE.', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-275', 'created_at': '2024-05-24T17:02:19.802+0530', 'updated_at': '2024-06-06T14:48:37.122+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Scenarios not properly captured when the requirement is having OBLIQUE. \\n Section 6.1.1 Forward slash sign is missing from the sentences. \\n\\nSentences extracted without the oblique slanting line and space (Point 6 - words are merged)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1794ee9d-e202-49f9-b883-22ebed381f0a', embedding=None, metadata={'id': '37369', 'title': 'Inconsistent in Coverage of Requirement', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-274', 'created_at': '2024-05-24T17:02:07.625+0530', 'updated_at': '2024-06-06T14:47:37.065+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Inconsistent in Coverage of Requirement \\n Scenarios not captured from the below sections in the requirement document\\n\\n5.1.4 to 5.1.7\\n\\nAttached the documents including the requirement and input and out put files', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='21fce726-6d5e-47c7-807a-e80b2d01e1cf', embedding=None, metadata={'id': '37365', 'title': 'Users should define the number of scenarios (Optional parameters)', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-272', 'created_at': '2024-05-24T15:54:31.010+0530', 'updated_at': '2024-06-03T11:35:25.287+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Users should define the number of scenarios (Optional parameters) \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ea50f138-b51e-45fa-a853-c9ad4a031bee', embedding=None, metadata={'id': '37364', 'title': 'Generate more test cases button', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-271', 'created_at': '2024-05-24T15:49:41.668+0530', 'updated_at': '2024-06-17T13:06:57.470+0530', 'labels': [], 'status': 'To Do', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Generate more test cases button \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b97a2cbc-2e35-4a7c-87ed-55761c9ed851', embedding=None, metadata={'id': '37256', 'title': 'Take db name from env var', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-269', 'created_at': '2024-05-20T11:05:38.582+0530', 'updated_at': '2024-06-06T14:43:06.663+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Take db name from env var \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='6564fbd4-0c7e-497a-bf69-62ae1fd539dd', embedding=None, metadata={'id': '37222', 'title': 'Auto scaling', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-268', 'created_at': '2024-05-17T11:24:16.144+0530', 'updated_at': '2024-05-28T11:40:10.661+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Auto scaling \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e66bea73-4a7d-4779-89dc-2a472e90a663', embedding=None, metadata={'id': '37221', 'title': 'Rerun API integration', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-267', 'created_at': '2024-05-17T11:14:34.591+0530', 'updated_at': '2024-05-21T17:34:46.344+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Rerun API integration \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a94c0bc1-80c3-4f11-a6c9-796960fc5d1b', embedding=None, metadata={'id': '37220', 'title': 'Revoke and grant access to user in edit user page', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-266', 'created_at': '2024-05-17T11:14:04.346+0530', 'updated_at': '2024-05-21T17:26:23.150+0530', 'labels': [], 'status': 'Done', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Revoke and grant access to user in edit user page \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.load_data(query=\"project = TAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee9c53e-257b-4068-861d-146a3d78c4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='1818ba91-857c-404e-9245-1886d63adb0a', embedding=None, metadata={'id': '38313', 'title': 'Lavage R&D', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-317', 'created_at': '2024-07-08T16:48:14.470+0530', 'updated_at': '2024-07-08T16:48:37.470+0530', 'labels': [], 'status': 'In Progress', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Lavage R&D \\n None', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7c2bed-1027-4951-b832-6ff26f341a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.metadata[\"document_type\"] = \"jira_issues\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "acff6184-5993-43e2-a991-124174827d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37883',\n",
       " 'title': 'Move coverage matrix to openai assistant',\n",
       " 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-303',\n",
       " 'created_at': '2024-06-17T13:07:14.100+0530',\n",
       " 'updated_at': '2024-06-17T13:07:55.359+0530',\n",
       " 'labels': [],\n",
       " 'status': 'In Progress',\n",
       " 'assignee': '',\n",
       " 'reporter': '',\n",
       " 'project': 'Tenjin_ai_core',\n",
       " 'issue_type': 'Task',\n",
       " 'priority': 'Lowest',\n",
       " 'epic_key': '',\n",
       " 'epic_summary': '',\n",
       " 'epic_description': '',\n",
       " 'document_type': 'jira_issues'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700aced8-51f2-4441-b07d-01ea39429589",
   "metadata": {},
   "source": [
    "# create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c13802-32bb-47f8-aed3-0592ce390453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "connection_string = \"postgresql://postgres:postgres@192.168.17.100:5432\"\n",
    "# connection_string = \"postgresql://postgres:Qwertgbnm123#@localhost:5432\"\n",
    "db_name = \"jira_vector_db\"\n",
    "conn = psycopg2.connect(connection_string)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966daa0-c75d-4032-baee-fbbb3a57b1ec",
   "metadata": {},
   "source": [
    "## vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163bd57a-9ba5-4987-9f3b-41a405318498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e3b96471864e1ba5ce4986ca79b702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0929b7c49f747e681cd9034be80727a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sqlalchemy import make_url\n",
    "\n",
    "url = make_url(connection_string)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"jiraisuuesvector\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83745d0-b71f-47e9-8a5e-23c48d31be3d",
   "metadata": {},
   "source": [
    "# fetch index from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d95555-cc82-4663-bf5f-f9a074a3dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVectorStore.from_params(\n",
    "    database=\"jira_vector_db\",\n",
    "    host=\"192.168.17.100\",\n",
    "    password=\"postgres\",\n",
    "    port=5432,\n",
    "    user=\"postgres\",\n",
    "    table_name=\"jiraisuuesvector\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae2d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-postgres\n",
      "  Using cached llama_index_vector_stores_postgres-0.1.11-py3-none-any.whl (7.3 kB)\n",
      "Collecting asyncpg<0.30.0,>=0.29.0\n",
      "  Using cached asyncpg-0.29.0-cp311-cp311-win_amd64.whl (543 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-vector-stores-postgres) (0.10.43.post1)\n",
      "Collecting pgvector<0.3.0,>=0.2.4\n",
      "  Using cached pgvector-0.2.5-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting psycopg2-binary<3.0.0,>=2.9.9\n",
      "  Using cached psycopg2_binary-2.9.9-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]<2.1,>=1.4.49 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-vector-stores-postgres) (2.0.30)\n",
      "Collecting async-timeout>=4.0.3\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.6.6)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.6.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.31.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.12.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy[asyncio]<2.1,>=1.4.49->llama-index-vector-stores-postgres) (3.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.7.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.16.0)\n",
      "Installing collected packages: psycopg2-binary, pgvector, async-timeout, asyncpg, llama-index-vector-stores-postgres\n",
      "Successfully installed async-timeout-4.0.3 asyncpg-0.29.0 llama-index-vector-stores-postgres-0.1.11 pgvector-0.2.5 psycopg2-binary-2.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374bc88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-openai\n",
      "  Using cached llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-embeddings-openai) (0.10.43.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.6)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.6.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.31.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.12.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.7.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
      "Installing collected packages: llama-index-embeddings-openai\n",
      "Successfully installed llama-index-embeddings-openai-0.1.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1511383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-openai\n",
      "  Using cached llama_index_llms_openai-0.1.23-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-openai) (0.10.43.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.6)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.6.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.31.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.12.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.7.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\kaaliraj\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kaaliraj\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
      "Installing collected packages: llama-index-llms-openai\n",
      "Successfully installed llama-index-llms-openai-0.1.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1ba93e-c6b8-4247-82df-0a0f01c89dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.postgres import PGVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b2005-3dc9-4b90-9676-e6bb0c825b03",
   "metadata": {},
   "source": [
    "# metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8905dc65-98e1-40df-9e17-f41e15512ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75ef3c20-0470-4e79-9a06-7d1d7839ecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Possible test scenarios could include:\\n1. Testing the integration of Jira with requirements documents for test design.\\n2. Verifying the functionality of linking Jira issues to specific test cases.\\n3. Testing the updating of test design documents based on changes in Jira issues.\\n4. Validating the synchronization of status updates between Jira and the test design documents.\\n5. Testing the assignment of tasks in Jira to specific team members responsible for test design.\\n6. Verifying the visibility of test design progress within Jira for stakeholders.\\n7. Testing the impact of changes in Jira issues on the overall test design process.\\n8. Validating the accuracy of data transfer between Jira and the test design documents.\\n9. Testing the notification system for any updates or changes related to test design in Jira.\\n10. Verifying the security measures in place to protect sensitive test design information within Jira.', source_nodes=[NodeWithScore(node=TextNode(id_='a4a497e8-06e0-4113-8cd9-ff1fbb14bf17', embedding=None, metadata={'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.', 'document_type': 'jira_issues'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='37be2305-a8e8-4375-91e2-8b9faa68bab8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.', 'document_type': 'jira_issues'}, hash='2d9871af98324c2f5abf5ac1344d2fa5ab4008ba9d8edac7ecee4059a9237d02')}, text='Jira Integration for requirements documents for test design \\n None', start_char_idx=0, end_char_idx=66, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7462844403812742)], metadata={'a4a497e8-06e0-4113-8cd9-ff1fbb14bf17': {'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.', 'document_type': 'jira_issues'}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    vector_store_query_mode=\"default\",\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            ExactMatchFilter(key=\"id\", value=\"37884\"),\n",
    "        ]\n",
    "    ),\n",
    "    alpha=None,\n",
    "    doc_ids=None,\n",
    ")\n",
    "response = query_engine.query(\"You are helpful assistant for test design, use the given context to generate all different possible meaningful test scenarios\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b3b0275-22a3-407d-b512-1cd398d3d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Possible test scenarios could include:\\n1. Verify that the Jira integration for requirements documents is functioning correctly.\\n2. Test if the test design documents are being updated accurately based on changes in Jira issues.\\n3. Validate that the status of the issue in Jira is reflected accurately in the test design documents.\\n4. Check if the assignee and reporter details are correctly synchronized between the test design and Jira.\\n5. Ensure that the priority of the task in Jira aligns with the priority of the test design document.\\n6. Confirm that any updates made to the epic key and summary in Jira are appropriately reflected in the test design.\\n7. Test the integration to ensure that any changes in the epic description in Jira are updated in the test design documents.', source_nodes=[NodeWithScore(node=TextNode(id_='a4a497e8-06e0-4113-8cd9-ff1fbb14bf17', embedding=None, metadata={'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.', 'document_type': 'jira_issues'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='37be2305-a8e8-4375-91e2-8b9faa68bab8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.', 'document_type': 'jira_issues'}, hash='2d9871af98324c2f5abf5ac1344d2fa5ab4008ba9d8edac7ecee4059a9237d02')}, text='Jira Integration for requirements documents for test design \\n None', start_char_idx=0, end_char_idx=66, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7462844403812742)], metadata={'a4a497e8-06e0-4113-8cd9-ff1fbb14bf17': {'id': '37884', 'title': 'Jira Integration for requirements documents for test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-304', 'created_at': '2024-06-17T13:10:49.320+0530', 'updated_at': '2024-07-01T11:09:32.124+0530', 'labels': [], 'status': 'In Progress', 'assignee': 'indirajith', 'reporter': 'indirajith', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': 'TAC-308', 'epic_summary': 'OpenAI Response is breaking (Continue)', 'epic_description': 'This issue is being actively worked on at the moment by the assignee.', 'document_type': 'jira_issues'}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6270d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module b7163aea-740b-4641-9859-150fc23d5e32 with input: \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 9df552fa-27f9-4204-9b10-06a312b26e76 with input: \n",
      "input: \n",
      "You are helpful assistant for test design, use the given context to generate all different possible meaningful test scenarios.Strictly Output with the following json format\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module e5b95a8b-b5d2-4154-b3be-1fce0411ff2e with input: \n",
      "input: {\n",
      "  \"test_scenarios\": [\n",
      "    \"Verify that the Jira integration for requirements documents is successfully completed\",\n",
      "    \"Verify that the Jira issue status is correctly updated to 'In Progress'\",\n",
      "    ...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Scenario_model(BaseModel):\n",
    "    \"\"\" Object representing a list of test case scenarios.\"\"\"\n",
    "    test_scenarios: List[str] = Field(..., description=\"List of Scenarios.\")\n",
    "\n",
    "# Initialize the output parser with your Pydantic model\n",
    "output_parser = PydanticOutputParser(Scenario_model)\n",
    "\n",
    "# Define your prompt template\n",
    "json_prompt_str = \"\"\"\n",
    "You are helpful assistant for test design, use the given context to generate all different possible meaningful test scenarios.Strictly Output with the following json format\n",
    "\"\"\"\n",
    "json_prompt_tmpl = PromptTemplate(json_prompt_str)\n",
    "\n",
    "# Initialize the query engine with filters\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    "    vector_store_query_mode=\"default\",\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            ExactMatchFilter(key=\"id\", value=\"37884\"),\n",
    "        ]\n",
    "    ),\n",
    "    alpha=None,\n",
    "    doc_ids=None,\n",
    ")\n",
    "\n",
    "# Initialize the pipeline with the correct chain of modules\n",
    "p = QueryPipeline(chain=[json_prompt_tmpl, query_engine, output_parser], verbose=True)\n",
    "\n",
    "# Now when you run the pipeline, it will query the index as part of processing the query\n",
    "output = p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8b677b6-2f25-4d28-978f-1c491de8e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Verify that the Jira integration for requirements documents is successfully completed', \"Verify that the Jira issue status is correctly updated to 'In Progress'\", 'Verify that the lowest priority task is being actively worked on by the assignee', 'Verify that the Jira issue is related to the Tenjin_ai_core project', 'Verify that the Jira issue type is a Task']\n"
     ]
    }
   ],
   "source": [
    "# Access the test_scenarios attribute\n",
    "test_scenarios = output.test_scenarios\n",
    "\n",
    "# Now test_scenarios is a list of strings\n",
    "print(test_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99360581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e672f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8cfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd76e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5c18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7851b0-e022-49fd-9ce2-77ea3a90eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c38ae382-355b-473f-8b06-8cc521f58c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory ../data/paul_graham/ does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n\u001b[1;32m----> 3\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/paul_graham/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:260\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[1;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_dir:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39misdir(input_dir):\n\u001b[1;32m--> 260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dir \u001b[38;5;241m=\u001b[39m _Path(input_dir)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;241m=\u001b[39m exclude\n",
      "\u001b[1;31mValueError\u001b[0m: Directory ../data/paul_graham/ does not exist."
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader.read_file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aed98e-0f78-4ef6-b0eb-30706f34ff45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba84b3-205f-4ff9-96d0-7c98b9ef3953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684046e8-66b7-4647-a7de-cce80609e3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde6e06-44b0-4b46-aee5-a6966a6db9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350869ad-b116-4c6c-85f6-096888f1023e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d650ed-6a21-4599-b394-3953d037ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57792f0a-2add-4348-96f2-cab83d626520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2601711-cdf4-458d-8105-8dfac4b086ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "text_qa_template_str = (\n",
    "    \"Context information is\"\n",
    "    \" below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing\"\n",
    "    \" both the context information and also using your own knowledge, answer\"\n",
    "    \" the question: {query_str}\\nIf the context isn't helpful, you can also\"\n",
    "    \" answer the question on your own.\\n\"\n",
    ")\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "\n",
    "refine_template_str = (\n",
    "    \"The original question is as follows: {query_str}\\nWe have provided an\"\n",
    "    \" existing answer: {existing_answer}\\nWe have the opportunity to refine\"\n",
    "    \" the existing answer (only if needed) with some more context\"\n",
    "    \" below.\\n------------\\n{context_msg}\\n------------\\nUsing both the new\"\n",
    "    \" context and your own knowledge, update or repeat the existing answer.\\n\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87b36b4f-7fb7-4527-ae08-9741b39974ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Along with free text, coverage checkpoints to be provided during generate more scenarios - Issue ID: 37628\n",
      "2. Send file id in response. Refer the screenshot - Issue ID: 37174\n",
      "3. Implement error handling for invalid user inputs - Issue ID: TBD\n",
      "4. Improve performance of data processing module - Issue ID: TBD\n",
      "5. Fix authentication issue for user login - Issue ID: TBD\n",
      "6. Enhance user interface for better user experience - Issue ID: TBD\n",
      "7. Update third-party libraries to latest versions for security patches - Issue ID: TBD\n",
      "8. Implement automated testing for regression testing - Issue ID: TBD\n",
      "9. Optimize database queries for faster data retrieval - Issue ID: TBD\n",
      "10. Implement logging mechanism for tracking system activities - Issue ID: TBD\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\n",
    "    index.as_query_engine(\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "    \n",
    "    ).query(\"what are the top 10 issues to be handled also share the issue id for added info and strictly generate 10 along with issue id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae4595-cbe5-41db-9deb-c54b97d1fc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d95a3f71-7e72-4f4b-9d88-7be2d82e32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.indices.vector_store.retrievers import (\n",
    "    VectorIndexAutoRetriever,\n",
    ")\n",
    "from llama_index.core.query_engine.retriever_query_engine import (\n",
    "    RetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.core.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "\n",
    "# Define the metadata for your Jira stories vector store\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Jira stories\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"title\",\n",
    "            type=\"str\",\n",
    "            description=\"The title of the Jira issue\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# build retriever\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index, vector_store_info=vector_store_info\n",
    ")\n",
    "\n",
    "# build query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever, response_synthesizer=get_response_synthesizer()\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\n",
    "    \"summarise the titles \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc4d07-3c58-4525-bc52-47a8beea3ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9736a5b9-8b2a-4202-9471-a02a73f58359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize the titles as \"sample issue created - testing the capability and integration with llama index\" and \"Inconsistent in Coverage of Requirement\".'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f89e9-6b22-4a5d-9eb3-0d5fc8981012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c244a7f-d72e-4d15-95ca-8db5b882f5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72c133-0a9e-48e8-87b1-465b7e71412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VectorStoreIndex.from_vector_store("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a6be098-e12c-4ca0-b96a-0b12e0d179c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_vector_index = index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5c054c6-bca4-4aba-b8dc-47f10dc8a22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='{\\n    \"title\": [\\n        \"User should be able to go back and select different set of scenarios to generate test cases\",\\n        \"Users should define the number of scenarios (Optional parameters)\"\\n    ]\\n}', source_nodes=[NodeWithScore(node=TextNode(id_='a5d29336-6008-459d-9f44-d4c848280107', embedding=None, metadata={'id': '37532', 'title': 'User should be able to go back and select different set of scenarios to generate test cases', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-287', 'created_at': '2024-06-03T11:42:41.628+0530', 'updated_at': '2024-06-05T11:03:15.440+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='bfdc5370-ae13-4d3e-823e-18e3ed398d13', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37532', 'title': 'User should be able to go back and select different set of scenarios to generate test cases', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-287', 'created_at': '2024-06-03T11:42:41.628+0530', 'updated_at': '2024-06-05T11:03:15.440+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, hash='73577b112b2e7a869d7e3150bb92c068833d160d32e421260b53b73b20679f14')}, text='User should be able to go back and select different set of scenarios to generate test cases \\n None', start_char_idx=0, end_char_idx=98, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8364303610581746), NodeWithScore(node=TextNode(id_='9bc70c85-9271-4c1a-a742-72b68b89a1e1', embedding=None, metadata={'id': '37365', 'title': 'Users should define the number of scenarios (Optional parameters)', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-272', 'created_at': '2024-05-24T15:54:31.010+0530', 'updated_at': '2024-06-03T11:35:25.287+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c036c502-bc58-4383-b4ed-dfa74c7b83a2', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37365', 'title': 'Users should define the number of scenarios (Optional parameters)', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-272', 'created_at': '2024-05-24T15:54:31.010+0530', 'updated_at': '2024-06-03T11:35:25.287+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, hash='8508e4c17cbd97b39ed1a8113cdba331d69c7c0144c34b3d3143fb4d84afaddf')}, text='Users should define the number of scenarios (Optional parameters) \\n None', start_char_idx=0, end_char_idx=72, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8244084820504033)], metadata={'a5d29336-6008-459d-9f44-d4c848280107': {'id': '37532', 'title': 'User should be able to go back and select different set of scenarios to generate test cases', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-287', 'created_at': '2024-06-03T11:42:41.628+0530', 'updated_at': '2024-06-05T11:03:15.440+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, '9bc70c85-9271-4c1a-a742-72b68b89a1e1': {'id': '37365', 'title': 'Users should define the number of scenarios (Optional parameters)', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-272', 'created_at': '2024-05-24T15:54:31.010+0530', 'updated_at': '2024-06-03T11:35:25.287+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_vector_index.as_query_engine().query(\"You are helpful assistant for test design, Please combine and generate all different possible meaningful test scenarios.generate in this JSON format: title (Don't change title name) as the key and a list of scenarios as the value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97c9b5-4299-4b8e-8db4-b5123c2ca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=3,\n",
    "    vector_store_query_mode=\"default\",\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            ExactMatchFilter(key=\"id\", value=\"paul graham\"),\n",
    "        ]\n",
    "    ),\n",
    "    alpha=None,\n",
    "    doc_ids=None,\n",
    ")\n",
    "response = query_engine.query(\"what did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9c4348c-1d3f-460d-a168-fe1eab137bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Test scenario: Verify that the Jira integration for requirements documents is successfully implemented and functional.\\n2. Test scenario: Validate that the Jira integration allows for easy access to requirements documents for test design purposes.\\n3. Test scenario: Confirm that the Jira integration for requirements documents enhances the efficiency of test design activities.\\n4. Test scenario: Ensure that the Jira integration for requirements documents maintains data integrity and accuracy during test design.\\n5. Test scenario: Check that the Jira integration for requirements documents provides seamless collaboration between team members involved in test design.\\n6. Test scenario: Validate that the Jira integration for requirements documents supports version control and tracking changes for test design iterations.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "542063b0-3ef2-4519-b486-619063ccfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "# List of values you want to filter by\n",
    "issue_ids = [\"37884\", \"37883\", \"37875\"]\n",
    "\n",
    "# Create a list of ExactMatchFilter instances for each author\n",
    "exact_match_filters = [ExactMatchFilter(key=\"id\", value=issue_id) for issue_id in issue_ids]\n",
    "\n",
    "# Update the query engine with the list of filters\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    "    vector_store_query_mode=\"default\",\n",
    "    filters=MetadataFilters(\n",
    "        filters=exact_match_filters\n",
    "    ),\n",
    "    alpha=None,\n",
    "    doc_ids=None,\n",
    ")\n",
    "\n",
    "# Perform the query\n",
    "response = query_engine.query(\"You are helpful assistant for test design, use the given context to generate all different possible meaningful test scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce0a59cc-be42-40e0-b3f7-4a72cdd59e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful: Empty Response\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "# List of values you want to filter by\n",
    "issue_ids = [\"37884\", \"37883\", \"37875\"]\n",
    "\n",
    "# Create a list of ExactMatchFilter instances for each issue ID\n",
    "exact_match_filters = [ExactMatchFilter(key=\"issue_id\", value=issue_id) for issue_id in issue_ids]\n",
    "\n",
    "# Update the query engine with the list of filters\n",
    "# Assuming 'index' is a previously defined object with an 'as_query_engine' method\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    "    vector_store_query_mode=\"default\",\n",
    "    filters=MetadataFilters(\n",
    "        filters=exact_match_filters\n",
    "    ),\n",
    "    alpha=None,\n",
    "    doc_ids=None,\n",
    ")\n",
    "\n",
    "# Perform the query\n",
    "# Assuming 'query_engine' has a 'query' method that takes a string and returns a response\n",
    "response = query_engine.query(\"You are helpful assistant for test design, use the given context to generate all different possible meaningful test scenarios\")\n",
    "\n",
    "# Check if the response is not None and print the result\n",
    "if response:\n",
    "    print(\"Query successful:\", response)\n",
    "else:\n",
    "    print(\"No response received. Please check the query and filters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6b5ee2-8bed-4a1e-b48e-1eb538e1fde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Empty Response', source_nodes=[], metadata=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adfb3a0f-f66b-4c72-b7e7-1529b0f61de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = team_vector_index.as_query_engine().query(\"You are helpful assistant for test design, Please combine and generate all different possible meaningful test scenarios. Use this context:\\n{context}\\nStrictly generate in this JSON format: title (Don't change title name) as the key and a list of scenarios as the value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb48863-c17e-455e-8594-1abefb52e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "'User should upload multiple files at a time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb185e59-8f44-4731-b1a4-c29dc617b02a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n\n[SQL: SELECT public.data_jiraisuuesvector.id, public.data_jiraisuuesvector.node_id, public.data_jiraisuuesvector.text, public.data_jiraisuuesvector.metadata_, public.data_jiraisuuesvector.embedding <=> %(embedding_1)s AS distance \nFROM public.data_jiraisuuesvector ORDER BY distance asc \n LIMIT %(param_1)s]\n[parameters: {'embedding_1': '[-0.023185420781373978,0.00947460625320673,0.03141617402434349,-0.005206413567066193,-0.012033389881253242,0.03397495672106743,-0.010775321163237095, ... (32527 characters truncated) ... -0.029283855110406876,-0.018679119646549225,-0.01913401484489441,0.012801025062799454,0.0026458532083779573,0.01022802572697401,-0.03852390497922897]', 'param_1': 2}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mteam_vector_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_query_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are helpful assistant for test design, Please combine and generate all different possible meaningful test scenarios. Use this context:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid is 37491\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mStrictly generate in this JSON format: context (Don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt change title name) as the key and a list of scenarios as the value.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:189\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    187\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[0;32m    188\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m--> 189\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_synthesizer\u001b[38;5;241m.\u001b[39msynthesize(\n\u001b[0;32m    191\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery_bundle,\n\u001b[0;32m    192\u001b[0m         nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:144\u001b[0m, in \u001b[0;36mRetrieverQueryEngine.retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[1;32m--> 144\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_node_postprocessors(nodes, query_bundle\u001b[38;5;241m=\u001b[39mquery_bundle)\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:243\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    240\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    241\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    242\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 243\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    245\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    246\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:101\u001b[0m, in \u001b[0;36mVectorIndexRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle\u001b[38;5;241m.\u001b[39membedding_strs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     96\u001b[0m         query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     97\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model\u001b[38;5;241m.\u001b[39mget_agg_embedding_from_queries(\n\u001b[0;32m     98\u001b[0m                 query_bundle\u001b[38;5;241m.\u001b[39membedding_strs\n\u001b[0;32m     99\u001b[0m             )\n\u001b[0;32m    100\u001b[0m         )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:177\u001b[0m, in \u001b[0;36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[1;34m(self, query_bundle_with_embeddings)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_nodes_with_embeddings\u001b[39m(\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[0;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[0;32m    176\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_vector_store_query(query_bundle_with_embeddings)\n\u001b[1;32m--> 177\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_node_list_from_query_result(query_result)\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\postgres\\base.py:752\u001b[0m, in \u001b[0;36mPGVectorStore.query\u001b[1;34m(self, query, **kwargs)\u001b[0m\n\u001b[0;32m    748\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_query_with_rank(\n\u001b[0;32m    749\u001b[0m         query\u001b[38;5;241m.\u001b[39mquery_str, sparse_top_k, query\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m    750\u001b[0m     )\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m VectorStoreQueryMode\u001b[38;5;241m.\u001b[39mDEFAULT:\n\u001b[1;32m--> 752\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid query mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\postgres\\base.py:503\u001b[0m, in \u001b[0;36mPGVectorStore._query_with_score\u001b[1;34m(self, embedding, limit, metadata_filters, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m     hnsw_ef_search \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhnsw_ef_search\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    498\u001b[0m     session\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    499\u001b[0m         text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSET hnsw.ef_search = :hnsw_ef_search\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    500\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhnsw_ef_search\u001b[39m\u001b[38;5;124m\"\u001b[39m: hnsw_ef_search},\n\u001b[0;32m    501\u001b[0m     )\n\u001b[1;32m--> 503\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    507\u001b[0m     DBEmbeddingRow(\n\u001b[0;32m    508\u001b[0m         node_id\u001b[38;5;241m=\u001b[39mitem\u001b[38;5;241m.\u001b[39mnode_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    514\u001b[0m ]\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2351\u001b[0m, in \u001b[0;36mSession.execute\u001b[1;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[0m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2292\u001b[0m     statement: Executable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2298\u001b[0m     _add_event: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result[Any]:\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[0;32m   2301\u001b[0m \n\u001b[0;32m   2302\u001b[0m \u001b[38;5;124;03m    Returns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2349\u001b[0m \n\u001b[0;32m   2350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2356\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2357\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2236\u001b[0m, in \u001b[0;36mSession._execute_internal\u001b[1;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mscalar(\n\u001b[0;32m   2232\u001b[0m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options\u001b[38;5;241m=\u001b[39mexecution_options\n\u001b[0;32m   2233\u001b[0m     )\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls:\n\u001b[1;32m-> 2236\u001b[0m     result: Result[Any] \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_state_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm_execute_statement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2237\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2245\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   2246\u001b[0m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options\u001b[38;5;241m=\u001b[39mexecution_options\n\u001b[0;32m   2247\u001b[0m     )\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\orm\\context.py:293\u001b[0m, in \u001b[0;36mAbstractORMCompileState.orm_execute_statement\u001b[1;34m(cls, session, statement, params, execution_options, bind_arguments, conn)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21morm_execute_statement\u001b[39m(\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m     conn,\n\u001b[0;32m    292\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result:\n\u001b[1;32m--> 293\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39morm_setup_cursor_result(\n\u001b[0;32m    297\u001b[0m         session,\n\u001b[0;32m    298\u001b[0m         statement,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m         result,\n\u001b[0;32m    303\u001b[0m     )\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1630\u001b[0m )\n\u001b[0;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1639\u001b[0m )\n\u001b[1;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1655\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m         ret,\n\u001b[0;32m   1660\u001b[0m     )\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2353\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2351\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2352\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1974\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1979\u001b[0m     )\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (psycopg2.OperationalError) server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n\n[SQL: SELECT public.data_jiraisuuesvector.id, public.data_jiraisuuesvector.node_id, public.data_jiraisuuesvector.text, public.data_jiraisuuesvector.metadata_, public.data_jiraisuuesvector.embedding <=> %(embedding_1)s AS distance \nFROM public.data_jiraisuuesvector ORDER BY distance asc \n LIMIT %(param_1)s]\n[parameters: {'embedding_1': '[-0.023185420781373978,0.00947460625320673,0.03141617402434349,-0.005206413567066193,-0.012033389881253242,0.03397495672106743,-0.010775321163237095, ... (32527 characters truncated) ... -0.029283855110406876,-0.018679119646549225,-0.01913401484489441,0.012801025062799454,0.0026458532083779573,0.01022802572697401,-0.03852390497922897]', 'param_1': 2}]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "response = team_vector_index.as_query_engine().query(\"You are helpful assistant for test design, Please combine and generate all different possible meaningful test scenarios. Use this context:\\n{'id is 37491'}\\nStrictly generate in this JSON format: context (Don't change title name) as the key and a list of scenarios as the value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8ff53ec-1806-4176-8a5e-478acfd9ff8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"context\": [\\n        \"User should be able to go back and select different set of scenarios to generate test cases\",\\n        \"User context with load more to be added to DB and displayed to user along with scenarios\"\\n    ]\\n}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8df147e4-a6d3-431b-b191-51d02cf19f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a5d29336-6008-459d-9f44-d4c848280107': {'id': '37532',\n",
       "  'title': 'User should be able to go back and select different set of scenarios to generate test cases',\n",
       "  'url': 'https://tenjin-automation.atlassian.net/browse/TAC-287',\n",
       "  'created_at': '2024-06-03T11:42:41.628+0530',\n",
       "  'updated_at': '2024-06-05T11:03:15.440+0530',\n",
       "  'labels': [],\n",
       "  'status': 'To Do',\n",
       "  'assignee': '',\n",
       "  'reporter': '',\n",
       "  'project': 'Tenjin_ai_core',\n",
       "  'issue_type': 'Task',\n",
       "  'priority': 'Lowest',\n",
       "  'epic_key': '',\n",
       "  'epic_summary': '',\n",
       "  'epic_description': ''},\n",
       " 'b4b2f7e2-ff6c-4d69-8ade-d27f47df7b8b': {'id': '37728',\n",
       "  'title': 'User context with load more to be added to DB and displayed to user along with scenarios',\n",
       "  'url': 'https://tenjin-automation.atlassian.net/browse/TAC-294',\n",
       "  'created_at': '2024-06-07T12:02:53.861+0530',\n",
       "  'updated_at': '2024-06-07T12:03:00.696+0530',\n",
       "  'labels': [],\n",
       "  'status': 'To Do',\n",
       "  'assignee': '',\n",
       "  'reporter': '',\n",
       "  'project': 'Tenjin_ai_core',\n",
       "  'issue_type': 'Task',\n",
       "  'priority': 'Lowest',\n",
       "  'epic_key': '',\n",
       "  'epic_summary': '',\n",
       "  'epic_description': ''}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92bd14ec-035e-4f27-b0d5-8606bbc72359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eac0d103-1beb-4db6-9819-3f842c7688c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1a3ff88-1ac4-489b-bd71-8138d12f074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaaliraj\\AppData\\Local\\Temp\\ipykernel_29568\\3106195878.py:7: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, chunk_size=chunk_size)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model selection\n",
    "model = \"gpt-4\"\n",
    "chunk_size = 2048\n",
    "\n",
    "# general configurations\n",
    "llm = OpenAI(temperature=0, model=model, streaming=True)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3d4cac5-58bb-499e-9f24-cccdca087c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import SQLAutoVectorQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.core.tools.query_engine import QueryEngineTool\n",
    "from llama_index.core.indices.vector_store import VectorIndexAutoRetriever\n",
    "from llama_index.core.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "team_vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"jira issues of tenjin ai team\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"title\",\n",
    "            type=\"str\",\n",
    "            description=\"The detail of the jira issue.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "team_vector_auto_retriever = VectorIndexAutoRetriever(\n",
    "    team_vector_index, vector_store_info=team_vector_store_info\n",
    ")\n",
    "\n",
    "team_retriever_query_engine = RetrieverQueryEngine.from_args(\n",
    "    team_vector_auto_retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2788957-e412-49d9-82b4-041a37d61de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd752af-3fd6-4de8-af25-3648baa490ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "894ef443-ba11-447a-911f-2277f8761a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The issues associated with test case generation include inconsistencies in the number of test scenarios and test cases generated for the same requirement document. This can lead to discrepancies in test coverage and potentially impact the thoroughness of testing efforts.\n"
     ]
    }
   ],
   "source": [
    "print(index.as_query_engine().query(\"what are the issues associated test case generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4f8dc-1083-499e-b431-cbf3479589e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.as_query_engine().query(\"what are the issues associated test case generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8db18f6-3cce-4aeb-b47a-8232330e9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"list all the rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00dab51-1003-410c-81b5-690edc710859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='There are two rows in the context information provided.', source_nodes=[NodeWithScore(node=TextNode(id_='55e30c1b-b0c5-4d35-af2b-72857833acf5', embedding=None, metadata={'id': '37040', 'title': 'All columns should be exported during export design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-254', 'created_at': '2024-05-13T11:16:27.090+0530', 'updated_at': '2024-05-13T12:12:45.321+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e48788ce-31da-4b0a-81b0-199dc69759d8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37040', 'title': 'All columns should be exported during export design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-254', 'created_at': '2024-05-13T11:16:27.090+0530', 'updated_at': '2024-05-13T12:12:45.321+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, hash='9d6d751ccedf12b9676cf816fd5d395d12c4b25f138c4393f8a8c973b88f04cd')}, text='All columns should be exported during export design \\n None', start_char_idx=0, end_char_idx=58, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7459228786276069), NodeWithScore(node=TextNode(id_='dc1d65c9-b11f-44f5-ad6b-d5161c9ff831', embedding=None, metadata={'id': '37046', 'title': 'Order of design with coverage matrix', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-256', 'created_at': '2024-05-13T12:29:15.121+0530', 'updated_at': '2024-06-17T12:09:51.749+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d4e9982-8832-4f1f-a2fc-dc70988390ec', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37046', 'title': 'Order of design with coverage matrix', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-256', 'created_at': '2024-05-13T12:29:15.121+0530', 'updated_at': '2024-06-17T12:09:51.749+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, hash='89e02bb426d6bf0a7406ae10a622fde492924ef69762adb638d501831d0594da')}, text='Order of design with coverage matrix \\n None', start_char_idx=0, end_char_idx=43, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7254299252712867)], metadata={'55e30c1b-b0c5-4d35-af2b-72857833acf5': {'id': '37040', 'title': 'All columns should be exported during export design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-254', 'created_at': '2024-05-13T11:16:27.090+0530', 'updated_at': '2024-05-13T12:12:45.321+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, 'dc1d65c9-b11f-44f5-ad6b-d5161c9ff831': {'id': '37046', 'title': 'Order of design with coverage matrix', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-256', 'created_at': '2024-05-13T12:29:15.121+0530', 'updated_at': '2024-06-17T12:09:51.749+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ab923dd-84dd-4911-b4cb-92c888477516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is one Jira issue in this vector base, which is identified by the id 37045 and has the title\n",
      "\"Duplication of test cases in test design.\"\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d286344-fef4-479d-92be-fa5d8ca36d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb2abe2a-2729-4c85-af3e-f71cf29890f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='There is one Jira issue based on the provided context information.', source_nodes=[NodeWithScore(node=TextNode(id_='d4b232ec-635c-4fa8-8dcc-e570d8412ebd', embedding=None, metadata={'id': '37529', 'title': 'Pagination', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-284', 'created_at': '2024-06-03T11:38:07.852+0530', 'updated_at': '2024-06-17T13:06:38.777+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ad9c9949-9abd-4989-96ef-94ecefa74a04', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37529', 'title': 'Pagination', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-284', 'created_at': '2024-06-03T11:38:07.852+0530', 'updated_at': '2024-06-17T13:06:38.777+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, hash='62ffad3a546cd051046d501fb925facc79fc2525241e27aac5e4352c5c6fa4f2')}, text='Pagination \\n None', start_char_idx=0, end_char_idx=17, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7967797750437551)], metadata={'d4b232ec-635c-4fa8-8dcc-e570d8412ebd': {'id': '37529', 'title': 'Pagination', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-284', 'created_at': '2024-06-03T11:38:07.852+0530', 'updated_at': '2024-06-17T13:06:38.777+0530', 'labels': [], 'status': 'To Do', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Task', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eedb0179-fc5c-48f4-ae1d-8c7b9b4c2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    vector_store_kwargs={\"ivfflat_probes\": 10},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de4f99bb-7b62-4e8e-b4b2-a3d20adfef63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DispatcherSpanMixin' from 'llama_index.core.instrumentation' (C:\\Users\\kaaliraj\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, get_response_synthesizer\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorIndexRetriever\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrieverQueryEngine\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityPostprocessor\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\retrievers\\__init__.py:47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfusion_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QueryFusionRetriever\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecursive_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveRetriever\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrouter_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RouterRetriever\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformRetriever\n\u001b[0;32m     50\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorIndexRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorIndexAutoRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseImageRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m ]\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\retrievers\\router_retriever.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Sequence\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRetriever\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_selector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSelector\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CBEventType, EventPayload\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n",
      "File \u001b[1;32m~\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_selector.py:9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_pipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     ChainableMixin,\n\u001b[0;32m      6\u001b[0m     QueryComponent,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbridge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minstrumentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DispatcherSpanMixin\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptMixin, PromptMixinType\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QueryBundle, QueryType\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DispatcherSpanMixin' from 'llama_index.core.instrumentation' (C:\\Users\\kaaliraj\\Downloads\\tenjin-ai\\jira-integration\\jiraiya\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "# build index\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"do you know that?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8de79b32-21e6-4b5b-9c39-24c01bd965af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='There is one Jira issue in this vector base, which is identified by the id 37045 and has the title \"Duplication of test cases in test design.\"', source_nodes=[NodeWithScore(node=TextNode(id_='778bfae1-3cc7-4588-9916-789f512bea31', embedding=None, metadata={'id': '37045', 'title': 'Duplication of test cases in test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-255', 'created_at': '2024-05-13T12:28:40.824+0530', 'updated_at': '2024-06-06T14:43:21.715+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b2e3353a-166a-416c-9bce-9b5a487f16ad', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'id': '37045', 'title': 'Duplication of test cases in test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-255', 'created_at': '2024-05-13T12:28:40.824+0530', 'updated_at': '2024-06-06T14:43:21.715+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}, hash='7845934b5f1242fc182cf5c73d854c03622b711929f89f17fdf3cbb3dcf89d6b')}, text='Duplication of test cases in test design \\n None', start_char_idx=0, end_char_idx=47, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7715846384809513)], metadata={'778bfae1-3cc7-4588-9916-789f512bea31': {'id': '37045', 'title': 'Duplication of test cases in test design', 'url': 'https://tenjin-automation.atlassian.net/browse/TAC-255', 'created_at': '2024-05-13T12:28:40.824+0530', 'updated_at': '2024-06-06T14:43:21.715+0530', 'labels': [], 'status': 'Done', 'assignee': '', 'reporter': '', 'project': 'Tenjin_ai_core', 'issue_type': 'Bug', 'priority': 'Lowest', 'epic_key': '', 'epic_summary': '', 'epic_description': ''}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92adc6-b067-4114-b94a-fe4a9438678b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
